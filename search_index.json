[["index.html", "Un paseo guiado por el algoritmo de Metrópolis Chapter 1 Introducción 1.1 Funcionamiento basico del algoritmo Metropolis y su relevancia en simulacion estadistica.", " Un paseo guiado por el algoritmo de Metrópolis Guillen García Marieth Agnes, Hernández López Idalia 2023-10-06 Chapter 1 Introducción A continuación, estudiaremos el algoritmo metropolis y su aplicación en la simulación estadística utilizando el lenguaje de programación R. Tomaremos como punto de partida la pagina web A guided walk through the metropolis algorithm y el articulo “Markov unchained: a guided walk through the Metropolis algorithm”. El Objetivo de este proyecto es comprender el funcionamiento de cada algoritmo implementado y complementar de manera descriptiva los ejemplos proporcionados en la pagina web para facilitar el tema al lector. 1.1 Funcionamiento basico del algoritmo Metropolis y su relevancia en simulacion estadistica. El algoritmo Metropolis es un esquema de Monte Carlo de cadena de Markov que se utiliza con frecuencia en problemas estadísticos bayesianos. Su objetivo es simular una cadena de Markov que tiene como distribución estacionaria la distribución posterior del problema en cuestión. La relevancia del algoritmo Metropolis en la simulación estadística radica en su capacidad para estimar cantidades de interés a partir de una distribución posterior compleja en un espacio de parámetros de alta dimensión. Este algoritmo permite a los investigadores obtener inferencias estadísticas a partir de distribuciones posteriores que no se pueden calcular analíticamente. Además, el algoritmo Metropolis es fácil de implementar y ha sido ampliamente utilizado en la práctica debido a su simplicidad y eficiencia. "],["definicion-de-variables-y-funciones-a-utilizar..html", "Chapter 2 Definicion de variables y funciones a utilizar. 2.1 Lectura de Datos 2.2 Funciones Auxiliares 2.3 Estimación de Máxima Verosimilitud", " Chapter 2 Definicion de variables y funciones a utilizar. 2.1 Lectura de Datos Para leer datos en R, se pueden utilizar diversas funciones y métodos según el formato en el que estén los datos o como se deseen trabajar. En la siguiente línea de código los datos que se proporcionan son un ejemplo de variables “y” y “x” que representan casos de leucemia y exposición: y = c(rep(1, 36), rep(0, 198)) # leukemia cases x = c(rep(1, 3), rep(0, 33), rep(1, 5), rep(0, 193)) # exposure Estos datos son típicos en análisis estadísticos y se utilizan para investigar si existe una relación entre la exposición y la ocurrencia de casos de leucemia, por ejemplo, mediante un modelo de regresión logística. La variable “y” sería la variable dependiente (casos de leucemia) y la variable “x” sería la variable independiente (exposición). 2.2 Funciones Auxiliares Estas funciones se utilizarán en todo momento puesto que son útiles para realizar cálculos específicos relacionados con modelos de regresión logística, como calcular la verosimilitud del modelo o la diferencia de riesgo entre grupos. #helper functions # calcula la función logística inversa expit &lt;- function(mu) 1/(1+exp(-mu)) # calcula el logaritmo de la verosimilitud de un modelo de regresión logistica loglik = function(y,x,beta){ # calculate the log likelihood lli = dbinom(y, 1, expit(beta[1] + x*beta[2]), log=TRUE) sum(lli) } # calcula la diferencia de riesgo entre dos grupos en el contexto de # un modelo de regresión logística binaria riskdifference = function(y, x, beta){ # baseline odds (offset) # calculate a risk difference poprisk = 4.8/100000 popodds = poprisk/(1-poprisk) studyodds = mean(y)/(1-mean(y)) r1 = expit(log(popodds/studyodds) + beta[1] + beta[2]) r0 = expit(log(popodds/studyodds) + beta[1]) mean(r1-r0) } 2.3 Estimación de Máxima Verosimilitud Es un método estadístico utilizado para estimar los parámetros de un modelo estadístico, busca encontrar los valores de los parámetros que maximizan la verosimilitud de que los datos observados sean generados por el modelo propuesto. A continuación, se presenta cómo funciona la estimación de máxima verosimilitud en R: # data se utiliza para ajustar un modelo de regresión logística binaria data = data.frame(leuk=y, magfield=x) # Ajuste del modelo de regresión logística, para predecir la relacion de las variables # indicar que se trata de un modelo binomial mod = glm(leuk ~ magfield, family=binomial(), data=data) # Resumen del modelo y extracción de coeficientes: summary(mod)$coefficients Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.766183 0.188373 -9.375988 6.853094e-21 magfield 1.255357 0.754200 1.664488 9.601492e-02 # Cálculo del coeficiente de regresión (beta) y su intervalo de confianza beta1 = summary(mod)$coefficients[2,1] # coeficente de regresión para magfield se1 = summary(mod)$coefficients[2,2] # Error estandar # Intervalo de confianza del 95% para coeficiente beta1 cat(&quot;\\n\\nMaximum likelihood beta coefficient (95% CI)\\n&quot;) Maximum likelihood beta coefficient (95% CI) round(c(beta=beta1, ll=beta1+se1*qnorm(0.025), ul=beta1+se1*qnorm(0.975)), 2) beta ll ul 1.26 -0.22 2.73 # Cálculo del odds ratio y su intervalo de confianza # El odds ratio permite interpretar la relación de probabilidades de éxito en # la variable dependiente para un cambio unitario en la variable independiente cat(&quot;\\n\\nMaximum likelihood odds ratio (95% CI)\\n&quot;) Maximum likelihood odds ratio (95% CI) round(exp(c(beta=beta1, ll=beta1+se1*qnorm(0.025), ul=beta1+se1*qnorm(0.975))), 2) beta ll ul 3.51 0.80 15.39 # Cálculo de la diferencia de riesgo (risk difference) multiplicada por 1000: # representa la dif en la probabilidad de éxito en la variable dependiente cat(&quot;\\n\\nMaximum likelihood risk difference (multiplied by 1000) \\n&quot;) Maximum likelihood risk difference (multiplied by 1000) round(c(rd_1000=riskdifference(y,x,mod$coefficients)*1000), 2) rd_1000 0.11 "],["metrópolis-de-paseo-aleatorio.html", "Chapter 3 Metrópolis de paseo aleatorio 3.1 Concepto y funcionamiento de algoritmo 3.2 Implentación en R 3.3 Resultados e interpretación", " Chapter 3 Metrópolis de paseo aleatorio 3.1 Concepto y funcionamiento de algoritmo El algoritmo de Paseo Aleatorio Metropolis (algoritmo Random Walk Metropolis en inglés) es un método de Monte Carlo Markov Chain (MCMC) utilizado para explorar distribuciones de probabilidad, especialmente en problemas de inferencia bayesiana. A continuación, se proporciona una explicación detallada de los conceptos y pasos relacionados con este algoritmo. Definición del problema: El algoritmo de Paseo Aleatorio Metropolis se utiliza para aproximar la distribución de probabilidad de una variable aleatoria de interés, dada una función objetivo o distribución objetivo. Esta distribución objetivo puede ser la distribución posterior en un problema de inferencia bayesiana. Generación de una cadena de Markov: El algoritmo de Paseo Aleatorio Metropolis genera una cadena de Markov, que es una secuencia de estados que evoluciona de acuerdo con ciertas reglas de transición. Cada estado de la cadena representa una posible configuración de la variable aleatoria de interés. Propuesta de un nuevo estado: En cada paso de la cadena, se propone un nuevo estado basado en el estado actual. En el caso del algoritmo de Paseo Aleatorio, el nuevo estado se obtiene agregando un ruido aleatorio al estado actual. Comúnmente, se utiliza una distribución normal para generar este ruido, con una media de cero y una variación que se ajusta para controlar la amplitud de los pasos. Evaluación de la aceptación: Una vez que se propone un nuevo estado, se evalúa si se acepta o se rechaza. Esto se hace calculando la razón de aceptación, que es la proporción entre la densidad de probabilidad de la distribución objetivo evaluada en el nuevo estado propuesto y la densidad de probabilidad evaluada en el estado actual. Si la razón de aceptación es mayor o igual a uno, se acepta el nuevo estado. Si es menor que uno, se acepta el nuevo estado con una probabilidad igual a la razón de aceptación. Actualización del estado: Si se acepta el nuevo estado, se actualiza el estado actual de la cadena con el nuevo estado propuesto. Si se rechaza, se mantiene. 3.2 Implentación en R # initialize M=10000 # Numero de muestras que se generarán en el algoritmo set.seed(91828) # Semilla para inicializar el generador de números aleatorios. beta_post = matrix(nrow=M, ncol=2) # Matriz para almacenar coeficientes del modelo colnames(beta_post) = c(&#39;beta0&#39;, &#39;beta1&#39;) # Se asgina nombres a las dos columnas accept = numeric(M) # vector númerico con M muestras rd = numeric(M) # vector númerico con M muestras beta_post[1,] = c(2,-3) # se establece la primera fila con valores iniciales (2, -3) rd[1] = riskdifference(y, x, beta_post[1,]) # dif. de riesgo de las estimaciones accept[1] = 1 # Vector para registrar si la muestra es aceptada (1) o rechazada (0) for(i in 2:M){ oldb = beta_post[i-1,] # almacena coeficiente de la muestra anterior prop = rnorm(2, sd=0.2) # Genera una muestra para nuevos coeficientes newb = oldb+prop # Calcula los nuevos coeficientes al sumar la propuesta num = loglik(y,x,newb) # Calculan el logaritmo de verosimilitud para newb den = loglik(y,x,oldb) # Calculan el logaritmo de verosimilitud para oldb acceptprob = exp(num-den) # calcula la /p de aceptar la nueva muestra acc = (acceptprob &gt; runif(1)) # aceptar o rechazar la nueva función anterior if(acc){ beta_post[i,] = newb # se almacenan si es aceptada accept[i] = 1 }else{ beta_post[i,] = oldb accept[i] = 0 } # Calcula y almacena la diferencia de riesgo para cada conjunto de estimaciones rd[i] = 1000*riskdifference(y, x, beta_post[i,]) } 3.3 Resultados e interpretación La variable accept se utiliza para hacer un seguimiento de cuántas de las muestras generadas son aceptadas por el algoritmo, esta variable proporciona una medida de la tasa de aceptación promedio durante todas las iteraciones del algoritmo, una tasa de aceptación de aproximadamente \\(0.6551\\) sugiere que el algoritmo de Metropolis-Hastings aceptó alrededor del \\(65.51\\%\\) de las muestras generadas, lo que generalmente es una tasa razonable y puede indicar un buen equilibrio entre la exploración eficaz y la convergencia en el espacio de parámetros. mean(accept) [1] 0.6551 El resumen estadístico de las muestras de los parámetros beta0 y beta1 revela información clave sobre la distribución de las estimaciones obtenidas a través del algoritmo. Para el parámetro \\(beta0\\), los valores varían desde aproximadamente \\(-2.518\\) hasta \\(2.000\\), con una mediana y media en torno a \\(-1.776\\) y \\(-1.770\\), respectivamente. En cuanto a \\(beta1\\), oscila entre \\(-3.9483\\) y \\(3.9189\\), con una mediana y media cercanas a \\(1.2292\\) y \\(1.1714\\). Estos estadísticos resaltan la variabilidad y proporcionan una estimación central de los parámetros. summary(beta_post) beta0 beta1 Min. :-2.518 Min. :-3.9483 1st Qu.:-1.902 1st Qu.: 0.7389 Median :-1.776 Median : 1.2292 Mean :-1.770 Mean : 1.1714 3rd Qu.:-1.651 3rd Qu.: 1.7004 Max. : 2.000 Max. : 3.9189 Se calcula la media de las muestras posteriores de beta0 y beta1, excluyendo las primeras \\(1000\\) muestras, esto se hace comúnmente para eliminar las iteraciones iniciales del algoritmo que pueden no haber convergido completamente y para obtener una estimación más precisa de la media posterior. El resultado indica que después de eliminar las primeras \\(1000\\) muestras (que a menudo se descartan como “quemado inicial”), la media posterior estimada para beta0 es aproximadamente \\(-1.78\\) y la media posterior para beta1 es aproximadamente \\(1.22\\). init = beta_post[1,] postmean = apply(beta_post[-c(1:1000),], 2, mean) cat(&quot;Posterior mean\\n&quot;, round(postmean, 2)) Posterior mean -1.78 1.22 El gráfico muestra visualmente cómo evolucionaron las muestras de los parámetros \\(beta0\\) y \\(beta1\\) a lo largo de las iteraciones del algoritmo, desde el valor inicial (Azul) hasta la media posterior (verde). Esto puede ayudar a comprender cómo convergieron las estimaciones y cómo se distribuyen las muestras posteriormente: plot(beta_post, pch=19, col=rgb(0,0,0,0.05), xlab=expression(beta[0]), ylab=expression(beta[1]), xlim=c(-2.5,2.5), ylim=c(-4.5,4.5)) points(init[1], init[2], col=&quot;deepskyblue2&quot;, pch=19) points(postmean[1], postmean[2], col=&quot;seagreen1&quot;, pch=19) legend(&quot;topright&quot;, col=c(&quot;deepskyblue2&quot;, &quot;seagreen1&quot;), legend=c(&quot;Initial value&quot;, &quot;Post. mean&quot;), pch=19) Muestra cómo cambian las estimaciones de \\(beta1\\) a medida que se ejecutan más iteraciones del algoritmo: plot(beta_post[,2], type=&#39;l&#39;, ylab=expression(beta[1]), xlab=&quot;Iteration&quot;, ylim=c(-4, 4)) Muestra cómo cambia la Diferencia de Riesgo multiplicada por \\(1000\\) a medida que se ejecutan más iteraciones del algoritmo. Este tipo de gráfico es útil para observar la convergencia de las estimaciones de la Diferencia de Riesgo a lo largo del tiempo y para evaluar la variabilidad en las estimaciones: plot(rd, type=&#39;l&#39;, ylab=&quot;RD*1000&quot;, xlab=&quot;Iteration&quot;, ylim=c(-4, 4)) Muestra cómo se distribuyen las estimaciones posteriores de beta1 después de eliminar el “quemado inicial”. Este tipo de gráfico es útil para visualizar la incertidumbre en las estimaciones de los parámetros y para identificar modas (picos) en la distribución: plot(density(beta_post[-c(1:1000),2]), xlab=expression(beta[1]), ylab=&quot;Density&quot;, main=&quot;&quot;) Muestra cómo se distribuyen las estimaciones de la Diferencia de Riesgo después de eliminar el “quemado inicial”. Este tipo de gráfico es útil para visualizar la incertidumbre en las estimaciones de la Diferencia de Riesgo y para identificar modas (picos) en la distribución: plot(density(rd[-c(1:1000)]), xlab=&quot;RD*1000&quot;, ylab=&quot;Density&quot;, main=&quot;&quot;) "],["metrópolis-guiada.html", "Chapter 4 Metrópolis guiada 4.1 Concepto y funcionamiento de algoritmo 4.2 Implentación en R 4.3 Resultados e interpretación", " Chapter 4 Metrópolis guiada 4.1 Concepto y funcionamiento de algoritmo El algoritmo de Paseo Guiado Metropolis es una variante del algoritmo Metropolis de Paseo Aleatorio que busca mejorar su eficiencia y convergencia. A continuación, se proporciona una explicación detallada de los conceptos y pasos relacionados con este algoritmo. Definición del problema: El algoritmo de Paseo Guiado Metropolis se utiliza para aproximar la distribución de probabilidad de una variable aleatoria de interés, dada una función objetivo o distribución objetivo. Esta distribución objetivo puede ser la distribución posterior en un problema de inferencia bayesiana. Generación de una cadena de Markov: Al igual que en el algoritmo de Paseo Aleatorio Metropolis, el algoritmo de Paseo Guiado Metropolis genera una cadena de Markov, que es una secuencia de estados que evoluciona de acuerdo con ciertas reglas de transición. Cada estado de la cadena representa una posible configuración de la variable aleatoria de interés. Propuesta de un nuevo estado: En cada paso de la cadena, se propone un nuevo estado basado en el estado actual. Sin embargo, a diferencia del algoritmo de Paseo Aleatorio Metropolis, en el algoritmo de Paseo Guiado Metropolis se utiliza una guía o dirección para generar el nuevo estado propuesto. Esta guía puede ser determinada por información adicional o conocimiento previo sobre la distribución objetivo. Evaluación de la aceptación: Una vez que se propone un nuevo estado, se evalúa si se acepta o se rechaza. Esto se hace calculando la razón de aceptación, que es la proporción entre la densidad de probabilidad de la distribución objetivo evaluada en el nuevo estado propuesto y la densidad de probabilidad evaluada en el estado actual. Si la razón de aceptación es mayor o igual a uno, se acepta el nuevo estado. Si es menor que uno, se acepta el nuevo estado con una probabilidad igual a la razón de aceptación. Actualización del estado: Si se acepta el nuevo estado, se actualiza el estado actual de la cadena con el nuevo estado propuesto. Si se rechaza el nuevo estado, se mantiene el estado actual sin cambios. 4.2 Implentación en R # initialize M=10000 # Numero de muestras que se generarán en el algoritmo set.seed(91828) # Semilla para inicializar el generador de números aleatorios beta_post_guide = matrix(nrow=M, ncol=2) # Matriz para almacenar coeficientes del modelo colnames(beta_post_guide) = c(&#39;beta0&#39;, &#39;beta1&#39;) # Se asgina nombres a las dos columnas accept = numeric(M) # vector númerico con M muestra rd_guide = numeric(M) # vector númerico con M muestra beta_post_guide[1,] = c(2,-3) # se establece la primera fila con valores iniciales (2, -3) rd_guide[1] = riskdifference(y,x,beta_post_guide[1,]) # dif. de riesgo de las estimaciones accept[1] = 1 # Vector para registrar si la muestra es aceptada (1) o rechazada (0) dir = 1 # Esta variable se utiliza para controlar la dirección de exploración for(i in 2:M){ oldb = beta_post_guide[i-1,] # almacena los coeficientes de la muestra anterior prop = dir*abs(rnorm(2, sd=0.2)) # muestra para nuevos coeficientes multiplicando por dir newb = oldb+prop # Calcula los nuevos coeficientes al sumar la propuesta num = loglik(y,x,newb) # Calculan el logaritmo de verosimilitud para newb den = loglik(y,x,oldb) # Calculan el logaritmo de verosimilitud para oldb acceptprob = exp(num-den) # calcula la /p de aceptar la nueva muestra acc = (acceptprob &gt; runif(1)) # aceptar o rechazar la nueva función anterior if(acc){ beta_post_guide[i,] = newb accept[i] = 1 }else{ beta_post_guide[i,] = oldb accept[i] = 0 # si la muestra es rechazada (acc == 0) dir = dir*-1 # se invierte la dirección dir multiplicándola por -1. # cambia la dirección de exploración en el espacio de parámetros. } # Calcula y almacena la diferencia de riesgo para cada conjunto de estimaciones rd_guide[i] = 1000*riskdifference(y,x,beta_post_guide[i,]) } # se calcula el valor del posterior promedio de los coeficientes # para las muestras posteriores a las primeras 1000 postmean = apply(beta_post_guide[-c(1:1000),], 2, mean) cat(&quot;Posterior mean, guided\\n&quot;, round(postmean, 2)) Posterior mean, guided -1.8 1.41 4.3 Resultados e interpretación Estos gráficos de traza se utilizan para visualizar cómo evolucionan las estimaciones de \\(beta1\\) a lo largo de las iteraciones y para comparar dos enfoques diferentes. La sobreposición de las trazas muestra cómo se comparan las estimaciones de ambos enfoques y si uno converge más rápido o es más efectivo: col1 = rgb(0,0,0,.5) col2 = rgb(1,0,0,.35) par(mfcol=c(1,2)) #trace plots plot(beta_post[1:200,2], type=&#39;l&#39;, ylab=expression(beta[1]), xlab=&quot;Iteration&quot;, ylim=c(-4, 4), col=col1) lines(beta_post_guide[1:200,2], col=col2) legend(&quot;topright&quot;, lty=1, col=c(col1, col2), legend=c(&quot;Rand. walk&quot;, &quot;Guided&quot;)) plot(9800:10000, beta_post[9800:10000,2], type=&#39;l&#39;, ylab=expression(beta[1]), xlab=&quot;Iteration&quot;, ylim=c(-4, 4), col=col1) lines(9800:10000, beta_post_guide[9800:10000,2], col=col2) legend(&quot;topright&quot;, lty=1, col=c(col1, col2), legend=c(&quot;Rand. walk&quot;, &quot;Guided&quot;)) Estos gráficos de densidad se utilizan para comparar visualmente las distribuciones de las estimaciones de beta1 y la Diferencia de Riesgo (RD) multiplicada por \\(1000\\) obtenidas mediante los dos enfoques r. Pueden ayudar a determinar si uno de los enfoques produce resultados más concentrados o si hay diferencias notables en las estimaciones posteriores: # density plots plot(density(beta_post_guide[-c(1:1000),2]), col=col2, xlab=expression(beta[1]), ylab=&quot;Density&quot;, main=&quot;&quot;) lines(density(beta_post[-c(1:1000),2]), col=col1) legend(&quot;bottomright&quot;, lty=1, col=c(col1, col2), legend=c(&quot;Rand. walk&quot;, &quot;Guided&quot;)) plot(density(rd_guide[-c(1:1000)]), xlab=&quot;RD*1000&quot;, ylab=&quot;Density&quot;, main=&quot;&quot;, col=col2) lines(density(rd[-c(1:1000)]), col=col1) legend(&quot;topright&quot;, lty=1, col=c(col1, col2), legend=c(&quot;Rand. walk&quot;, &quot;Guided&quot;)) par(mfcol=c(1,1)) "],["algoritmo-de-metrópolis-guiado-y-adaptativo.html", "Chapter 5 Algoritmo de metrópolis guiado y adaptativo 5.1 Concepto y funcionamiento de algoritmo 5.2 Implentación en R 5.3 Resultados e interpretación", " Chapter 5 Algoritmo de metrópolis guiado y adaptativo 5.1 Concepto y funcionamiento de algoritmo El algoritmo Metrópolis Guiado y Adaptativo es una variante del algoritmo Metrópolis-Hastings que busca mejorar la eficiencia y convergencia del muestreo de Monte Carlo Markov Chain (MCMC). A continuación, se proporciona una explicación detallada de los conceptos y pasos relacionados con este algoritmo. Definición del problema: El algoritmo Metrópolis Guiado y Adaptativo se utiliza para aproximar la distribución de probabilidad de una variable aleatoria de interés, dada una función objetivo o distribución objetivo. Esta distribución objetivo puede ser la distribución posterior en un problema de inferencia bayesiana. Generación de una cadena de Markov: Al igual que en el algoritmo Metrópolis-Hastings, el algoritmo Metrópolis Guiado y Adaptativo genera una cadena de Markov, que es una secuencia de estados que evoluciona de acuerdo con ciertas reglas de transición. Cada estado de la cadena representa una posible configuración de la variable aleatoria de interés. Propuesta de un nuevo estado: En cada paso de la cadena, se propone un nuevo estado basado en el estado actual. Sin embargo, a diferencia del algoritmo Metrópolis-Hastings estándar, en el algoritmo Metrópolis Guiado y Adaptativo se utiliza una guía o dirección para generar el nuevo estado propuesto. Esta guía puede ser determinada por información adicional o conocimiento previo sobre la distribución objetivo. Evaluación de la aceptación: Una vez que se propone un nuevo estado, se evalúa si se acepta o se rechaza. Esto se hace calculando la razón de aceptación, que es la proporción entre la densidad de probabilidad de la distribución objetivo evaluada en el nuevo estado propuesto y la densidad de probabilidad evaluada en el estado actual. Si la razón de aceptación es mayor o igual a uno, se acepta el nuevo estado. Si es menor que uno, se acepta el nuevo estado con una probabilidad igual a la razón de aceptación. Actualización del estado: Si se acepta el nuevo estado, se actualiza el estado actual de la cadena con el nuevo estado propuesto. Si se rechaza el nuevo estado, se mantiene el estado actual sin cambios. Adaptación de la Propuesta: Una característica clave del algoritmo Metrópolis Guiado y Adaptativo es la adaptación de la propuesta de salto. La desviación estándar de la distribución de salto se ajusta automáticamente durante el proceso de muestreo para mejorar la eficiencia del algoritmo. 5.2 Implentación en R # initialize M=10000 # Se generan 10000 muestras en total burnin=1000 # se defne la cantidad de iteracion inicial set.seed(91828) # se establece la semilla beta_post_adaptguide = matrix(nrow=M+burnin, ncol=2) #Matriz para almacenar coeficientes del modelo colnames(beta_post_adaptguide) = c(&#39;beta0&#39;, &#39;beta1&#39;) # designar nombres a las columnas accept = numeric(M+burnin) # vector numerico de las M muestras + las iteraciones rd_adaptguide = numeric(M+burnin) # vector numerico de las M muestras + las iteraciones beta_post_adaptguide[1,] = c(2,-3) # se establece la primera fila con valores iniciales (2, -3) rd_adaptguide[1] = riskdifference(y,x,beta_post[1,]) # dif. de riesgo de las estimaciones accept[1] = 1 # Vector para registrar si la muestra es aceptada (1) o rechazada (0) prop.sigma = c(0.2, 0.2) # Vector con desviaciones estandar iniciales dir = 1 # Esta variable se utiliza para controlar la dirección de exploración for(i in 2:(M+burnin)){ if((i &lt; burnin) &amp; (i &gt; 25)){ prop.sigma = apply(beta_post_adaptguide[max(1, i-100):(i-1),], 2, sd) } # si 25 &gt; i &lt; 1000 se calcula SD de muestras anteriores para guiar la propuesta. oldb = beta_post_adaptguide[i-1,] # almacena los coeficientes de la muestra anterior prop = dir*abs(rnorm(2, sd=prop.sigma)) # propuesta nuevo coeficiente * dir newb = oldb+prop # Calcula los nuevos coeficientes al sumar la propuesta num = loglik(y,x,newb) # Calculan el logaritmo de verosimilitud para newb den = loglik(y,x,oldb) # Calculan el logaritmo de verosimilitud para oldb acceptprob = exp(num-den) # calcula la probabilidad de aceptar la newb acc = (acceptprob &gt; runif(1)) # aceptar o rechazar la nueva función anterior if(acc){ beta_post_adaptguide[i,] = newb accept[i] = 1 # se almacenan si es aceptada }else{ beta_post_adaptguide[i,] = oldb accept[i] = 0 dir = dir*-1 # se invierte la dirección dir multiplicándola por -1. # cambia la dirección de exploración en el espacio de parámetros. } # Calcula y almacena la diferencia de riesgo para cada conjunto de estimaciones rd_adaptguide[i] = 1000*riskdifference(y,x,beta_post_adaptguide[i,]) } # luego del período de &quot;burn-in&quot; se calcula el valor # del posterior promedio de los coeficientes postmean = apply(beta_post_adaptguide[-c(1:1000),], 2, mean) cat(&quot;Posterior mean, guided and adaptive\\n&quot;, round(postmean, 2)) Posterior mean, guided and adaptive -1.78 1.22 5.3 Resultados e interpretación Estos gráficos proporcionan una visualización de cómo se están comportando las cadenas de Markov generadas por dos métodos diferentes. Puedes observar cómo evolucionan las trazas a lo largo de las iteraciones y si convergen hacia valores estables. La comparación entre los dos métodos ayuda a evaluar la eficacia del enfoque guiado y adaptativo en comparación con la caminata aleatoria: col1 = rgb(0,0,0,.5) col2 = rgb(1,0,0,.35) par(mfcol=c(1,2)) #trace plots plot(beta_post[1:200,2], type=&#39;l&#39;, ylab=expression(beta[1]), xlab=&quot;Iteration&quot;, ylim=c(-4, 4), col=col1) lines(beta_post_adaptguide[1:200,2], col=col2) legend(&quot;topright&quot;, lty=1, col=c(col1, col2), legend=c(&quot;Rand. walk&quot;, &quot;Guided, adaptive&quot;)) plot(9800:10000, beta_post[9800:10000,2], type=&#39;l&#39;, ylab=expression(beta[1]), xlab=&quot;Iteration&quot;, ylim=c(-4, 4), col=col1) lines(9800:10000, beta_post_adaptguide[9800:10000,2], col=col2) legend(&quot;topright&quot;, lty=1, col=c(col1, col2), legend=c(&quot;Rand. walk&quot;, &quot;Guided, adaptive&quot;)) Estos gráficos de densidad permiten comparar las distribuciones de dos conjuntos de datos, uno generado mediante el método de caminata aleatoria estándar y otro mediante el método guiado y adaptativo: # density plots plot(density(beta_post_adaptguide[-c(1:1000),2]), col=col2, xlab=expression(beta[1]), ylab=&quot;Density&quot;, main=&quot;&quot;) lines(density(beta_post[-c(1:1000),2]), col=col1) legend(&quot;bottomright&quot;, lty=1, col=c(col1, col2), legend=c(&quot;Rand. walk&quot;, &quot;Guided, adaptive&quot;)) plot(density(rd_adaptguide[-c(1:1000)]), xlab=&quot;RD*1000&quot;, ylab=&quot;Density&quot;, main=&quot;&quot;, col=col2) lines(density(rd[-c(1:1000)]), col=col1) legend(&quot;topright&quot;, lty=1, col=c(col1, col2), legend=c(&quot;Rand. walk&quot;, &quot;Guided, adaptive&quot;)) par(mfcol=c(1,1)) "],["conclusiones.html", "Chapter 6 Conclusiones", " Chapter 6 Conclusiones En conclusión, el algoritmo Metropolis es un método eficiente y ampliamente utilizado en la simulación estadística para estimar cantidades de interés a partir de distribuciones posteriores complejas. La relevancia del algoritmo Metropolis radica en su capacidad para representar de manera precisa la distribución objetivo y su velocidad de convergencia a la distribución estacionaria. Su funcionamiento básico, implica generar propuestas de transición y actualizar el estado actual de acuerdo con la probabilidad de aceptación, nos permite obtener inferencias estadísticas en problemas donde la distribución posterior no se puede calcular analíticamente. "],["referencias.html", "Chapter 7 Referencias", " Chapter 7 Referencias [Gustafson(1998)] P. Gustafson. A guided walk metropolis algorithm. Statistics and computing, 8:357–364, 1998. Horowitz, AM (1991) Un algoritmo de Monte Carlo guiado generalizado. Letras de Física B, 268, 247-252. Roberts, GO, Gelman, A. y Gilks, W. (1997) Convergencia débil y escalamiento óptimo de algoritmos de Metropolis de paseo aleatorio. Los Anales de Probabilidad Aplicada, 7(1), 110-120. Roberts, GO y Rosenthal, JS (1998) Escalado óptimo de aproximaciones discretas a difusiones de Langevin. Revista de la Royal Statistical Society: Serie B (Metodología estadística), 60(1), 255-268. Roberts, GO y Rosenthal, JS (2001) Escalado óptimo para varios algoritmos de Metropolis-Hastings. Ciencia estadística, 16(4), 351-367. Roberts, GO y Rosenthal, JS (2004) Cadenas de Markov en el espacio de estados generales y algoritmos MCMC. Encuestas de probabilidad, 1, 20-71. Roberts, GO y Rosenthal, JS (2009) Ejemplos de MCMC adaptativo. Revista de estadística gráfica y computacional, 18 (2), 349-367. Muller, P. y Ríos Insua, D. (1995) Problemas en el análisis bayesiano de modelos de redes neuronales. Documento de trabajo 95±31, Instituto de Estadística y Ciencias de la Decisión, Universidad de Duke. Tierney, L. (1994) Cadenas de Markov para explorar distribuciones posteriores (con discusión). Revista de la Royal Statistical Society B, 55, 3±23. Besag, J., Green, P., Higdon, D. y Mengersen, K. (1995) Computación bayesiana y sistemas estocásticos (con discusión). Ciencia estadística, 10, 3±36. Horowitz, AM (1991) Un algoritmo de Monte Carlo guiado generalizado. Letras de Física B, 268, 247±252. Roberts, GO, Gelman, A. y Gilks, W. (1997) Convergencia débil y escalamiento óptimo de algoritmos de Metropolis de paseo aleatorio. Anales de probabilidad aplicada, 7, 110 ± 120. Gustafson, P. (1998) A guided walk Metropolis algorithm. Statistics and Computing, 8(4), 357-364 Equipo de Desarrollo de R (2021). “metropolis: An R Package for Metropolis-Hastings Sampling”. Recuperado de: https://cran.r-project.org/web/packages/metropolis/vignettes/metropolis-vignette.html "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
